{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы владеем сетью магазинов, в которых продаются различные товары.  \n",
    "\n",
    "Наши сотрудники собрали датасет из 8523 продаж товаров в различных магазинах нашей сети. Наша задача построить модель, предсказывающую продажи каждого продукта в конкретном магазине.  \n",
    "\n",
    "Используя эту модель, попробовать выявить факторы, больше всего влияющие на увеличение продаж.  \n",
    "\n",
    "Описание датасета:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable\tDescription  \n",
    "- Item_Identifier\tId продукта  \n",
    "- Item_Weight\tВес продукта  \n",
    "- Item_Fat_Content\tСодержание жира в продукте  \n",
    "- Item_Visibility\t%полок, отведенный под наш продукт в конкретном магазине  \n",
    "- Item_Type\tКатегория продукта  \n",
    "- Item_MRP\tМаксимальная цена продажи продукта  \n",
    "- Outlet_Identifier\tИдентификатор магазина  \n",
    "- Outlet_Establishment_Year\tГод открытия магазина  \n",
    "- Outlet_Size\tПлощадь магазина  \n",
    "- Outlet_Location_Type\tТип города, в котором расположен магазин  \n",
    "- Outlet_Type\tПризнак является ли магазин продуктовым или супермаркетом  \n",
    "- Item_Outlet_Sales\tПродажи продукта в конкретном магазине. Именно ее и надо предсказывать  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате работы должен получиться:  \n",
    "- Jupyter-ноутбук с моделью  \n",
    "- Признаки, влияющие больше всего на уровень продаж  \n",
    "- Датасет, если после ваших манипуляций он отличается от исходного;  \n",
    "- Документ с обоснованием решения и краткими результатами: какие техники и почему использовали, что получили, что можно улучшить (можно в рамках jupyter notebook’а)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баллы\tЧто надо сделать  \n",
    "10\tПровести EDA  \n",
    "10\tОбработать категориальные признаки   \n",
    "10\tУстранить пропущенные значения  \n",
    "10\tИзучить корреляцию признаков с данными о продажах  \n",
    "10\tВыбрать и обосновать метрику, на основе которой будем измерять качество полученной модели  \n",
    "20\tПостроить и подобрать оптимальные параметры для любой линейной модели  \n",
    "20\tПостроить и подобрать оптимальные параметры для любой нелинейной модели  \n",
    "20\tПровести стекинг нескольких моделей  \n",
    "10\tОценить качество модели на отложенной выборке  \n",
    "10\tВыбрать топ 3 признака больше всего влияющие на объемы продаж  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все шаги решения должны сопровождаться подробным описанием полученных результатов и обоснованием выбора того или иного шага!  \n",
    "За отсутствие описания так же будут снижаться баллы.  \n",
    "\n",
    "Максимальное доступное количество баллов - 130  \n",
    "Для получения зачета надо набрать минимум 80 баллов  \n",
    "Для получения зачета с отличием надо набрать минимум 120 баллов  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Провести EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим глазами основные характеристики датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_cat = data.select_dtypes(object).columns\n",
    "columns_digit = data.select_dtypes(exclude=object).columns\n",
    "\n",
    "print(f'Количество категориальных переменных: {len(columns_cat)}')\n",
    "print(f'Количество количественных переменных: {len(columns_digit)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всего в датасете 8523 записей\n",
    "# среднее по целевому признаку составляет 2 181,29; при этом есть очень большо разбор - от 33,29 до 13 086,96\n",
    "\n",
    "# есть странный min=0 у признака Item_Visibility, а может и не странный\n",
    "# есть нулевые значения в признаках Item_Weight, Outlet_Size\n",
    "# много категорильных переменных, необходимо с ними поработать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Устранить пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Item_Weight.isna() == 1].count()\n",
    "data[data.Item_Weight.isna() == 1]\n",
    "\n",
    "# 1463 нулевых значения; 6113 ненулевых значения; \n",
    "# гипотезы:\n",
    "# - это продукты, вес которых реально очень низок. Можно уставить нулевыи или заполнить отрицательным значением\n",
    "# - значение на самом деле есть, но по какой-то причине отсутствуют. Необходимо проставить или предсказать значения признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Item_Weight.isna() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.Item_Weight.isna() == 1].Item_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data.Item_Weight.isna() == 0].Item_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.merge(pd.DataFrame(y), pd.DataFrame(x), how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кардинального различия по группам продуктов между продуктами со значениями и без нет. \n",
    "# скорее всего вес у этих позиций какой-то все же есть, либо он просто менее имеющегося \"минимума\" 4,555 по признаку, но \n",
    "# утверждать это нельзя. \n",
    "\n",
    "# Можно пробовать заполнить нули через предсказания отдельной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим копию датафрейма для работа с моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_cat = tmp_df[columns_cat].astype(str)\n",
    "tmp_df_digit = tmp_df[columns_digit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_cat = tmp_df_cat.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = tmp_df_digit.join(tmp_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предварительно отделим категориальные переменные от количественных\n",
    "# так как передать в модель текустовые признаки нельзя, то используем LableEncoder для перевода текста в цифру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобьем датасет на две части - по которой будем предсказывать вес и на которой будем обучаться. \n",
    "# Отдельно убираем признак Outlet_Size, так как в нем есть нули и мы хотим их отдельно предсказывать. \n",
    "\n",
    "iw_null = tmp_df[tmp_df.Item_Weight.isna() == 1].drop(['Item_Weight','Outlet_Size'], axis=1)\n",
    "\n",
    "iw_data = tmp_df[tmp_df.Item_Weight.isna() == 0].drop(['Item_Weight','Outlet_Size'], axis=1)\n",
    "iw_data_target = tmp_df[tmp_df.Item_Weight.isna() == 0].Item_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отдельно разобьем \"рабочие\" данные на обучающую и тестовую выборки \n",
    "X_train, X_test, y_train, y_test  = train_test_split(iw_data, iw_data_target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в качестве предсказательной модели возьмем RF из-за его лояльности к отсутствию OHE признаков.  \n",
    "rf_iw = RandomForestRegressor(n_estimators=500,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_iw.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_iw = rf_iw.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions_iw))\n",
    "\n",
    "# модель отработала; получили довольно низкий RMSE при средней по признаку 12,85. Прескажем реальные веса при помощи модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_iw_real = rf_iw.predict(iw_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.Item_Weight.loc[iw_null.index] = predictions_iw_real\n",
    "data.Item_Weight.loc[iw_null.index] = predictions_iw_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### построили модель RFRegressor`а для предсказания нулевых значений весов и заполнили их. \n",
    "# предположим, что это лучше, чем просто угадывать или заполнять нулями пустые значения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlet_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Outlet_Size.isna() == 1].count()\n",
    "data[data.Outlet_Size.isna() == 1]\n",
    "\n",
    "# 2410 нулевых значения; 6 113 ненулевых значения; \n",
    "# гипотезы:\n",
    "# - это островки, которые реально не имеют признака. Можно уставить нулевыи или заполнить отрицательным значением\n",
    "# - значение на самом деле есть, но по какой-то причине отсутствуют. Необходимо предсказать значения признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поопробуем посмотреть различия по Outlet_Location_Type и Outlet_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.Outlet_Size.isna() == 1].Outlet_Location_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data.Outlet_Size.isna() == 0].Outlet_Location_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pd.DataFrame(y), pd.DataFrame(x), how='outer', left_index=True, right_index=True).plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.Outlet_Size.isna() == 1].Outlet_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = data[data.Outlet_Size.isna() == 0].Outlet_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pd.DataFrame(y), pd.DataFrame(x), how='outer', left_index=True, right_index=True).plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### явно сказать, что отсутствующие признаки относятся к какому-то конкретному типу нельзя\n",
    "# попробуем построить классификатор для определения этого признака\n",
    "# тиакже воспользуемся моделью RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_null = tmp_df[tmp_df.Outlet_Size == 3].drop(['Item_Weight','Outlet_Size'], axis=1)\n",
    "\n",
    "os_data = tmp_df[tmp_df.Outlet_Size != 3].drop(['Item_Weight','Outlet_Size'], axis=1)\n",
    "os_data_target = tmp_df[tmp_df.Outlet_Size != 3].Outlet_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для подсчета метрики качества используем label_binarize на целевую переменную\n",
    "\n",
    "os_data_target = label_binarize(os_data_target, classes=[0, 1, 2])\n",
    "n_classes = os_data_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(os_data, os_data_target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для работы с несколькими классами применим OneVsRestClassifier, в качестве предсказывающей модели RF \n",
    "\n",
    "clf_os = OneVsRestClassifier(RandomForestClassifier(n_estimators=100,n_jobs=-1))\n",
    "y_score = clf_os.fit(X_train, y_train).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужно оценить получившиеся результаты, в качестве удобного и понятного средства оценки используем ROC AUC\n",
    "# и ниже начались танцы с расчетом и визуализацией ROC_AUC для мультиклассовой классификации..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test == y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### кривая явно либо ошибочная, либо говорит о переобучении, но не смог прежположить каой-то лучшй способ измерить. :(\n",
    "### в итоге оставим эту модель для заполнения нулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_os_real = np.argmax(clf_os.predict(os_null), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.Outlet_Size.loc[os_null.index] = predictions_os_real\n",
    "data.Outlet_Size.loc[os_null.index] = predictions_os_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# категорий мало, поэтому явно вернем их в изначальный текст\n",
    "\n",
    "data.Outlet_Size = np.where(data['Outlet_Size'] == 0, 'High', \n",
    "                        np.where(data['Outlet_Size'] == 1, 'Medium', \n",
    "                        np.where(data['Outlet_Size'] == 2, 'Small', data['Outlet_Size'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нулевые значения заполнены при помощи модели регрессирова и модели классификатора\n",
    "# возвращен оригинальный датасет с категориальными признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработать количественные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = data[columns_digit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# большинство количественных признаков выглядит нормально, нулевых значений нет. Тем не менее, почти по каждому признаку \n",
    "# очень много уникальных значений. Это можно создать сложности для обучения модели. Попробуем округлить незначащие сотые \n",
    "# или тысячные и посмотреть на изменения пространства признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item_Weight\n",
    "df_cont.Item_Weight.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_cont.Item_Weight.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont[df_cont.Item_Weight < 10].Item_Weight.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из-за точного веса в граммах получается очень большое количество уникальных признаков. \n",
    "# При этом при округлении их количество можно значитльно снизить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.Item_Weight = df_cont.Item_Weight.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item_Visibility\n",
    "df_cont.Item_Visibility.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_cont.Item_Visibility.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.Item_Visibility.round(2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.Item_Visibility = df_cont.Item_Visibility.round(2)\n",
    "# при помощи округления удается сузить пространство признака до 34 разновидностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Item_MRP\n",
    "df_cont.Item_MRP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_cont.Item_MRP.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.Item_MRP.round(0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.Item_MRP = df_cont.Item_MRP.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlet_Establishment_Year\n",
    "df_cont.Outlet_Establishment_Year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_cont.Outlet_Establishment_Year.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# значений немного, логически они выглядят нормальными. Не будем трогать признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Item_Outlet_Sales\n",
    "df_cont.Item_Outlet_Sales.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_cont.Item_Outlet_Sales.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы не знаем в каких единицах дана информация, поэтому значения после запятой в продажах могут быть значительны. \n",
    "# так как это наша целевая переменная, то стараемся сохранить максимум информации и не производить трансформацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработать категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Item_Identifier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Item_Fat_Content.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Item_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Identifier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Location_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# с виду с признаками все нормально. \n",
    "# Для деревьев можно сделать только OneHotEncoding, но для оценки также другими алгоритмами при помощи get dummies \n",
    "# преобразуем категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.get_dummies(data[columns_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Изучить корреляцию признаков с данными о продажах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для оценки корреляции между признаками используем визуализированную матрицу корреляций\n",
    "# в качестве данных возьмем датасет с предыдущего шага до любого рода get_dummies или ohe признаков. \n",
    "\n",
    "sns.heatmap(tmp_df.corr(), annot=True, cmap='RdYlGn', linewidths=0.1)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(35,35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Коррекляции в данных есть. Между целевой переменной и item mrp, между другими пермененными. Тем не менее, \n",
    "# некоторые признаки действительно логически пересекаются, но не взаимоисключаемы. Нельзя сказатЬ, что какой-то \n",
    "# признак явно вычисляется через другие. Оставим их. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cont.join(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получили итоговый df для работы с предсказаниями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбрать и обосновать метрику, на основе которой будем измерять качество полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Решаем задачу регрессии, поэтому можно для оценки выбирать один из показателей отклонения остатков - MAE, MSE, RMSE. \n",
    "# Отдельно мне хотелось бы избежать крупных ошибок модели, поэтому в качестве основного используем показатель RMSE.\n",
    "# тем не менее, отдельно посчитаем MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрали выборку для обучения, выбрали целевую переменную\n",
    "\n",
    "X = df.drop('Item_Outlet_Sales', axis=1)\n",
    "y = df['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобьем данные на отложенную выборку и обучающую\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отдельно обучающую выборку разобьем на трейн и тест\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построить и подобрать оптимальные параметры для любой линейной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для подбора оптимальных параметров (лучшей комбинации) используем GridSearchCV\n",
    "# итоговое поле признаков достаточно велико. Какие-то возможно не являются значимыми, поэтому в качестве линейной модели \n",
    "# используем Lasso регрессию с регуляризацией, которая зануляет коэффициенты перед наименее важными переменными "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_Lasso = {\n",
    "    'fit_intercept' : [False, True],\n",
    "    'normalize' : [False, True]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Lasso = GridSearchCV(Lasso(), param_grid=params_Lasso, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_Lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_Lasso.best_params_)\n",
    "print('RMSE: {}'.format(np.sqrt(np.abs(grid_Lasso.best_score_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# что-то получилось. Простое среднее по признаку 2181.28, наша ошибка как правило меньше. Посмотрим другие модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построить и подобрать оптимальные параметры для любой нелинейной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в качестве нелинейной модели я выбрал SVR из-за возможности попробовать разные ядра и попытаться найти наилучшее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svr = {\n",
    "    'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svr = GridSearchCV(SVR(), param_grid=params_svr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_svr.best_params_)\n",
    "print('RMSE: {}'.format(np.sqrt(np.abs(grid_svr.best_score_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# результат подбора SVR параметров - линейное ядро, отсюда похожая оценки работа модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Провести стекинг нескольких моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для реализации стекинга используем штатный алгоритм StackingRegressor и наполним его LR, SVR, KNN моделями, в качестве \n",
    "# решающего применим RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = StackingRegressor(\n",
    "    [\n",
    "        ('lr', LinearRegression()),\n",
    "        ('svm', SVR()),\n",
    "        ('knn',KNeighborsRegressor())\n",
    "    ],\n",
    "RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.named_estimators_['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = classifier.named_estimators_['lr'].predict(X_test)\n",
    "y_pred_svm = classifier.named_estimators_['svm'].predict(X_test)\n",
    "y_pred_knn = classifier.named_estimators_['knn'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE lr: \\t\", round(np.sqrt(mean_squared_error(y_test, y_pred_lr)),2))\n",
    "print(\"RMSE svm: \\t\", round(np.sqrt(mean_squared_error(y_test, y_pred_svm)),2))\n",
    "print(\"RMSE classifier: \\t\", round(np.sqrt(mean_squared_error(y_test, y_pred)),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценить качество модели на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предскажем значения на отложенной выборке и оценим метрику качестве\n",
    "y_pred_val_lr = classifier.named_estimators_['lr'].predict(X_val)\n",
    "y_pred_val_svm = classifier.named_estimators_['svm'].predict(X_val)\n",
    "y_pred_val_knn = classifier.named_estimators_['knn'].predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE lr: \\t\", round(np.sqrt(mean_squared_error(y_val, y_pred_val_lr)),2))\n",
    "print(\"RMSE svm: \\t\", round(np.sqrt(mean_squared_error(y_val, y_pred_val_svm)),2))\n",
    "print(\"RMSE KNN classifier: \\t\", round(np.sqrt(mean_squared_error(y_val, y_pred_val_knn)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_val.index, y_val, 'o', markersize = 5)\n",
    "plt.plot(y_val.index, y_pred_val, 'y^', markersize = 3)\n",
    "plt.title('Правильные и предсказанные значения продаж')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.final_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(len(classifier.final_estimator_.feature_importances_)),\n",
    "                 classifier.final_estimator_.feature_importances_)\n",
    "plt.yticks(np.arange(len(classifier.final_estimator_.feature_importances_)),classifier.estimators_)\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наибольшее влияние при выьоре итогового предсказания оказывает KNN, при этом по показателю ошибки LinearRegression\n",
    "# показывает просто катастрофу. Изменение/донастройка/замена этой модели из стекинга может улучшить или значительно изменить\n",
    "# качество предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбрать топ 3 признака больше всего влияющие на объемы продаж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
